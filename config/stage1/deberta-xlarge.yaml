data:
  directory: resources/train_xml
  max_length: 1400
  replace_prob: 0.05
  num_folds: 5
  fold_index: 0
  random_seed: 27

model:
  transformer:
    pretrained_model_name_or_path: microsoft/deberta-xlarge
    hidden_dropout_prob: 0.0
    attention_probs_dropout_prob: 0.0
  random_seed: 27

optim:
  optimizer:
    lr: 8e-6
    betas: [0.9, 0.98]
    eps: 1e-6
    weight_decay: 0.01
  scheduler:
    name: linear
    num_warmup_steps: 0
    num_training_steps: 1000

train:
  name: deberta-xlarge
  batch_size: 8
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  gradient_checkpointing: true
  validation_interval: 0.01
  log_every_n_steps: 1
  evaluate_start_step: 700
